{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from rapidfuzz import process, fuzz\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_map = {\n",
    "        \"Chennai Super Kings\": \"CSK\",\n",
    "        \"Mumbai Indians\": \"MI\",\n",
    "        \"Royal Challengers Bangalore\": \"RCB\",\n",
    "        \"Kolkata Knight Riders\": \"KKR\",\n",
    "        \"Rajasthan Royals\": \"RR\",\n",
    "        \"Sunrisers Hyderabad\": \"SRH\",\n",
    "        \"Delhi Capitals\": \"DC\",\n",
    "        \"Punjab Kings\": \"PBKS\",\n",
    "        \"Lucknow Super Giants\": \"LSG\",\n",
    "        \"Gujarat Titans\": \"GT\",\n",
    "        \"Royal Challengers Bengaluru\":\"RCB\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_price(price_str):\n",
    "    if not isinstance(price_str, str):\n",
    "        return np.nan\n",
    "    crore_match = re.search(r'([\\d.]+)\\s*crore', price_str, re.IGNORECASE)\n",
    "    lakh_match = re.search(r'([\\d.]+)\\s*lakh', price_str, re.IGNORECASE)\n",
    "    if crore_match:\n",
    "        value = float(crore_match.group(1))\n",
    "        return value\n",
    "    elif lakh_match:\n",
    "        value = float(lakh_match.group(1))\n",
    "        return value/100\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_player_data(st_year, end_year, type):\n",
    "    player_data = []\n",
    "    for year in range(st_year, end_year):\n",
    "        if type == 'replacement':\n",
    "                if year == 2022 or year == 2025:\n",
    "                    url3  = f'https://en.wikipedia.org/wiki/List_of_{year}_Indian_Premier_League_personnel_changes'\n",
    "                    response3 = requests.get(url3)\n",
    "                    soup3 = BeautifulSoup(response3.text, 'html.parser')\n",
    "                    head_tag3  = soup3.find('h2', id=\"Withdrawn_players\")\n",
    "                    table3 = head_tag3.find_next('table')\n",
    "                    table_df3 = pd.read_html(StringIO(str(table3)))[0]\n",
    "                    table_df3.rename(columns={table_df3.columns[5]: 'Player Name',table_df3.columns[6]: 'Price'}, inplace=True)\n",
    "                    table_df3['Team'] = table_df3['Team'].map(team_map)\n",
    "                    table_df3['Price'] = table_df3['Price'].apply(convert_price)\n",
    "                    table_df3 = table_df3[['Team','Player Name','Price']]\n",
    "                    table_df3['Year'] = year\n",
    "                    table_df3['Replacement'] = 'Yes'\n",
    "                    table_df3 = table_df3[table_df3['Price'].notna()].reset_index(drop=True)\n",
    "                    player_data.append(table_df3)\n",
    "                else:\n",
    "                    url3  = f'https://en.wikipedia.org/wiki/List_of_{year}_Indian_Premier_League_personnel_changes'\n",
    "                    response3 = requests.get(url3)\n",
    "                    soup3 = BeautifulSoup(response3.text, 'html.parser')\n",
    "                    head_tag3  = soup3.find('h2', id=\"Withdrawn_players\")\n",
    "                    table3 = head_tag3.find_next('table')\n",
    "                    table_df3 = pd.read_html(StringIO(str(table3)))[0]\n",
    "                    table_df3.rename(columns={table_df3.columns[6]: 'Player Name',table_df3.columns[8]: 'Price'}, inplace=True)\n",
    "                    table_df3['Team'] = table_df3['Team'].map(team_map)\n",
    "                    table_df3['Price'] = table_df3['Price'].apply(convert_price)\n",
    "                    table_df3 = table_df3[['Team','Player Name','Price']]\n",
    "                    table_df3['Year'] = year\n",
    "                    table_df3['Replacement'] = 'Yes'\n",
    "                    table_df3 = table_df3[table_df3['Price'].notna()].reset_index(drop=True)\n",
    "                    player_data.append(table_df3)\n",
    "        else:\n",
    "            url = f'https://sports.ndtv.com/ipl-{year}/auction/{type}'\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            teams = ['CSK', 'DC', 'MI',\n",
    "                    'LSG', 'GT', 'KKR',\n",
    "                    'PBKS', 'RR', 'RCB',\n",
    "                    'SRH']\n",
    "\n",
    "            for team in teams:\n",
    "                table = soup.find('table', id=re.compile(team))\n",
    "                table_df = pd.read_html(StringIO(str(table)))[0]\n",
    "                table_df['Player Name'] = table_df.apply(lambda row: row['Player Name'].replace(row['Type'], '').strip(), axis=1)\n",
    "                table_df['Team'] = team\n",
    "                table_df['Year'] = year\n",
    "                if type == 'retainedplayer':\n",
    "                    table_df['Retained'] = 'Yes'\n",
    "                    table_df['Price'] = table_df['Salary (₹ Cr.)']\n",
    "                    table_df = table_df[['Player Name','Team','Year','Price','Retained']]\n",
    "                else:\n",
    "                    table_df['Price'] = table_df['Price (₹ Cr.)']\n",
    "                    table_df['Replacement'] = 'No'\n",
    "                    table_df = table_df[['Player Name','Team','Year','Price','Replacement']]\n",
    "                player_data.append(table_df)\n",
    "            \n",
    "    return pd.concat(player_data,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retained_df = scrape_player_data(2022,2026,'retainedplayer')\n",
    "squad_df = scrape_player_data(2022,2026,'teamsquad')\n",
    "replacement_df = scrape_player_data(2022,2026,'replacement')\n",
    "squad_df = pd.concat([squad_df,replacement_df],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_df['Player Name'] = squad_df['Player Name'].str.replace(r'[^a-zA-Z\\s]$', '', regex=True)\n",
    "final_df = pd.merge(\n",
    "        squad_df,\n",
    "        retained_df[['Player Name', 'Team', 'Year','Retained']],\n",
    "        on=['Player Name', 'Team', 'Year'],\n",
    "        how='left'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Retained'] = final_df['Retained'].fillna('No')\n",
    "final_df['Price'] = final_df['Price'].astype(float)\n",
    "player_rep ={'Ravisrinivasan Sai Kishore':'Sai Kishore',\n",
    "'Vyshak Vijay Kumar':'Vijaykumar Vyshak',\n",
    "'Kumar Kartikeya Singh':'Kumar Kartikeya',\n",
    "\"Will O’Rourke\":\"Will O'Rourke\",\n",
    "'Srikar Bharat':'KS Bharat',\n",
    "'Yudhvir Charak':'Yudhvir Singh',\n",
    "'Harpreet Singh Bhatia':'Harpreet Singh',\n",
    "'Abhishek Porel':'Abishek Porel',\n",
    "'AM Ghazanfar':'Allah Ghazanfar',\n",
    "'D Ferreira':'Donovan Ferreira',\n",
    "'Josh Little':'Joshua Little',\n",
    "'M. Siddharth':'Manimaran Siddharth',\n",
    "'Mohammad Shami':'Mohammed Shami',\n",
    "'Philip Salt':'Phil Salt'\n",
    "}\n",
    "missing_player = {'Player Name':'Saurav Chuahan','Team':'RCB','Year':2024,'Price':0.20,'Replacement':'No','Retained':'No'}\n",
    "missing_player_df = pd.DataFrame([missing_player])\n",
    "final_df = pd.concat([final_df,missing_player_df],ignore_index=True)\n",
    "final_df['Player Name'] = final_df['Player Name'].replace(player_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_tables = []\n",
    "for year in range(2022,2026):\n",
    "    df = pd.read_csv(f'Player_data/IPL{year}PlayerAuction.csv')\n",
    "    copy = final_df[final_df['Year']==year].copy()\n",
    "    merged_df = pd.merge(\n",
    "            copy,\n",
    "            df,\n",
    "            on=['Player Name'],\n",
    "            how='left'\n",
    "        )\n",
    "    merged_tables.append(merged_df)\n",
    "squad_df = pd.concat(merged_tables,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_df['Base Price'] = squad_df['Base Price']/100\n",
    "squad_df['Role'] = squad_df['Role'].str.title()\n",
    "squad_df['Role'] = squad_df['Role'].replace('Batter', 'Batsman')\n",
    "squad_df['Bowling Style']= squad_df['Bowling Style'].str.title()\n",
    "squad_df.to_csv('data_files/IPLSquads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_names(name):\n",
    "    parts = name.strip().split()\n",
    "    if len(parts) < 2:\n",
    "        return name\n",
    "    first_initial = parts[0][0].upper() + parts[0][-1].upper()\n",
    "    last_name = parts[-1].title()\n",
    "    return f\"{first_initial} {last_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = []\n",
    "for filename in os.listdir('matches'):\n",
    "    with open(f'matches/{filename}') as f:\n",
    "        data = json.load(f)\n",
    "        date = data['info']['dates'][0]\n",
    "        team1, team2 = data['info']['players'].items()\n",
    "        d1 = {'Player Name':team1[1],'Team':team_map.get(team1[0]),'Year':date[0:4]}\n",
    "        d2 = {'Player Name':team2[1],'Team':team_map.get(team2[0]),'Year':date[0:4]}\n",
    "        df1= pd.DataFrame(d1)\n",
    "        df2= pd.DataFrame(d2)\n",
    "        tables.append(df1)\n",
    "        tables.append(df2)\n",
    "json_df = pd.concat(tables,ignore_index=True)\n",
    "json_df = json_df.drop_duplicates().reset_index(drop=True)\n",
    "json_df['Year'] = json_df['Year'].astype(int)\n",
    "\n",
    "dict={}\n",
    "for filename in os.listdir('matches'):\n",
    "    with open(f'matches/{filename}') as f:\n",
    "        data = json.load(f)\n",
    "    reg = data['info']['registry']['people']\n",
    "    dict.update(reg)\n",
    "\n",
    "player_names = set(json_df['Player Name'].str.strip().str.lower())\n",
    "player_dict = { key:value for key, value in dict.items() if key.strip().lower() in player_names}\n",
    "player_df = pd.DataFrame(list(player_dict.items()), columns=['Player Name', 'Player ID'])\n",
    "json_df = pd.merge(json_df,player_df,on=['Player Name'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_map = {'CV Varun':'Varun Chakravarthy','PWH de Silva':'Wanindu Hasaranga','PHKD Mendis':'Kamindu Mendis',\n",
    "              'PVSN Raju':'Satyanarayana Raju','DS Rathi':'Digvesh Singh','Rasikh Salam':'Rasikh Dar',\n",
    "              'PWA Mulder':'Wiaan Mulder','M Shahrukh Khan':'Shahrukh Khan','BKG Mendis': 'Kusal Mendis'}\n",
    "json_df['Player Name']= json_df['Player Name'].replace(player_map)\n",
    "json_df['Norm_names'] = json_df['Player Name'].apply(norm_names)\n",
    "squad_df['Norm_names'] = squad_df['Player Name'].apply(norm_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_match_with_team_year(player_name, team, year, squad_df, threshold=80):\n",
    "    filtered_squad = squad_df[(squad_df['Team'] == team) & (squad_df['Year'] == year)]\n",
    "    if filtered_squad.empty:\n",
    "        return None  \n",
    "    choices = filtered_squad['Norm_names'].tolist()\n",
    "    match, score, _ = process.extractOne(player_name, choices, scorer=fuzz.token_sort_ratio)\n",
    "\n",
    "    return match if score >= threshold else None\n",
    "json_df['Matched_Name'] = json_df.apply(lambda row: fuzzy_match_with_team_year(player_name=row['Norm_names'],team=row['Team'],year=row['Year'],squad_df=squad_df),axis=1)\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    json_df,\n",
    "    squad_df,\n",
    "    left_on=['Matched_Name', 'Team', 'Year'],\n",
    "    right_on=['Norm_names', 'Team', 'Year'],\n",
    "    how='left',\n",
    "    suffixes=('_json', '_squad')\n",
    ")\n",
    "\n",
    "squad_final_df = merged_df.drop(['Norm_names_json','Matched_Name','Norm_names_squad'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_final_df.to_csv('data_files/IPLPlayingSquads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_tables = pd.DataFrame()\n",
    "for year in range(2022,2026):\n",
    "    url = f'https://sports.ndtv.com/ipl-{year}/points-table'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    tag = soup.find('h1', class_='scr_pg-ttl')\n",
    "    table = tag.find_next('table')\n",
    "    table_df = pd.read_html(StringIO(str(table)))[0]\n",
    "    table_df.drop('Unnamed: 9',axis=1,inplace=True)\n",
    "    table_df = table_df[table_df['No'] != table_df['P']].reset_index(drop=True)\n",
    "    table_df['Teams'] = table_df['Teams'].apply(lambda x: x.split(' ')[-1])\n",
    "    table_df.rename(columns={'No':'Position'},inplace=True)\n",
    "    table_df['Year'] = year\n",
    "    table_df.rename(columns={'Teams':'Team'},inplace=True)\n",
    "    url2 = f'https://en.wikipedia.org/wiki/{year}_Indian_Premier_League'\n",
    "    response2 = requests.get(url2)\n",
    "    soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "    tag2 = soup2.find('h2' if year == 2023 else 'h3', id='Match_summary')\n",
    "    table2 = tag2.find_next('table')\n",
    "    table_df2 = pd.read_html(StringIO(str(table2)))[0]\n",
    "    table_df2.columns = table_df2.columns.get_level_values(1)\n",
    "    table_df2 = table_df2[['Team','Q1','E','Q2','F']]\n",
    "    table_df2['Team'] = table_df2['Team'].map(team_map)\n",
    "    final_df = pd.merge(\n",
    "    table_df,\n",
    "    table_df2,\n",
    "    on=['Team'],\n",
    "    how='left')\n",
    "    team_tables = pd.concat([team_tables,final_df],ignore_index=True)\n",
    "\n",
    "team_tables.to_csv('data_files/IPLTablesData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delivries_data(filename):\n",
    "    with open(f'matches/{filename}', 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    match_id = filename.replace('.json', '')\n",
    "    all_deliveries = []\n",
    "    teams = data['info']['teams']\n",
    "    for j,inning_data in enumerate(data.get('innings', [])):\n",
    "        team_batting = inning_data['team']\n",
    "        team_bowling = [team for team in teams if team != team_batting][0]\n",
    "        is_super_over = inning_data.get('super_over', False)\n",
    "        for over_data in inning_data.get('overs', []):\n",
    "            over_number = over_data['over']\n",
    "            for i, delivery in enumerate(over_data.get('deliveries', [])):\n",
    "                wicket_info = delivery.get('wickets', [{}])[0]\n",
    "                fielder = wicket_info.get('fielders',{})\n",
    "                delivery_dict = {\n",
    "                    'match_id': match_id,\n",
    "                    'inning': j+1,\n",
    "                    'is_super_over':is_super_over,\n",
    "                    'batting_team': team_map.get(team_batting),\n",
    "                    'bowling_team': team_map.get(team_bowling),\n",
    "                    'over': over_number,\n",
    "                    'ball': i + 1,\n",
    "                    'batter': delivery.get('batter'),\n",
    "                    'non_striker': delivery.get('non_striker'),\n",
    "                    'bowler': delivery.get('bowler'),\n",
    "                    'runs_off_bat': delivery.get('runs', {}).get('batter', 0),\n",
    "                    'extras': delivery.get('runs', {}).get('extras', 0),\n",
    "                    'extras_type': ', '.join(delivery.get('extras', {}).keys()) if delivery.get('extras') else None,\n",
    "                    'total_runs': delivery.get('runs', {}).get('total', 0),\n",
    "                    'is_wicket': 1 if 'wickets' in delivery else 0,\n",
    "                    'player_out': wicket_info.get('player_out'),\n",
    "                    'kind': wicket_info.get('kind'),\n",
    "                    'fielder_name': fielder[0].get('name') if fielder else None\n",
    "                }\n",
    "                all_deliveries.append(delivery_dict)\n",
    "                \n",
    "    return pd.DataFrame(all_deliveries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_summary(filename, deliveries_df):\n",
    "    so_match_summary_df = None\n",
    "    with open(f'matches/{filename}', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        info = data['info']\n",
    "        innings = data.get('innings', [])\n",
    "        match_id = filename.replace('.json', '')\n",
    "        main_innings_df = deliveries_df[~deliveries_df['is_super_over']]\n",
    "        main_scores = main_innings_df.groupby('batting_team').agg(runs=('total_runs', 'sum'),wickets=('is_wicket', 'sum'),balls = ('ball','count')).reset_index()\n",
    "        team1_name = deliveries_df.loc[deliveries_df['inning'] == 1, 'batting_team'].iloc[0]\n",
    "        team2_name = deliveries_df.loc[deliveries_df['inning'] == 1, 'bowling_team'].iloc[0]\n",
    "        winner = info.get('outcome', {}).get('winner',{})\n",
    "        event_list = list(data['info']['event'].items())[1]\n",
    "        team_1_balls_faced = main_scores[main_scores['batting_team'] == team1_name]['balls'].iloc[0]\n",
    "        summary = {\n",
    "            'match_id': match_id,\n",
    "            'winner': team_map.get(winner) if winner else 'No Result',\n",
    "            'venue': info.get('venue'),\n",
    "            'year':datetime.strptime(info['dates'][0],'%Y-%m-%d').date().year,\n",
    "            'toss_winner': team_map.get(info.get('toss', {}).get('winner')),\n",
    "            'toss_decision': info.get('toss', {}).get('decision'),\n",
    "            'match_type': 'Group Stage' if event_list[0] == 'match_number' else event_list[1],\n",
    "            'team_1': team1_name,\n",
    "            'team_1_score': main_scores[main_scores['batting_team'] == team1_name]['runs'].iloc[0],\n",
    "            'team_1_wickets': main_scores[main_scores['batting_team'] == team1_name]['wickets'].iloc[0],\n",
    "            'team_1_balls_faced': team_1_balls_faced if team_1_balls_faced<120 else 120 ,}\n",
    "        if len(innings) < 2:\n",
    "            summary.update({\n",
    "            'team_2': team2_name,\n",
    "            'team_2_score': 0,\n",
    "            'team_2_wickets': 0,\n",
    "            'team_2_balls_faced':0})\n",
    "        else:\n",
    "            team_2_balls_faced = main_scores[main_scores['batting_team'] == team2_name]['balls'].iloc[0]\n",
    "            summary.update({\n",
    "                'team_2':team2_name,\n",
    "                'team_2_score': main_scores[main_scores['batting_team'] == team2_name]['runs'].iloc[0],\n",
    "                'team_2_wickets': main_scores[main_scores['batting_team'] == team2_name]['wickets'].iloc[0],\n",
    "                'team_2_balls_faced': team_2_balls_faced if team_2_balls_faced<120 else 120})\n",
    "        if len(innings) > 2:\n",
    "            super_over_df = deliveries_df[deliveries_df['is_super_over']]\n",
    "            so_scores = super_over_df.groupby('batting_team').agg(runs=('total_runs', 'sum'), wickets=('is_wicket', 'sum'),balls = ('ball','count')).reset_index()\n",
    "            so_team1_name = team_map.get(innings[2]['team'])\n",
    "            so_team2_name = team_map.get(innings[3]['team'])\n",
    "            so_match_summary={\n",
    "            'match_id': match_id,\n",
    "            'winner': team_map.get(info.get('outcome', {}).get('eliminator',{})),\n",
    "            'is_so_match':True,\n",
    "            'so_team1_name':so_team1_name,\n",
    "            'so_team2_name':so_team2_name,\n",
    "            'so_team1_score': so_scores[so_scores['batting_team']==so_team1_name]['runs'].iloc[0],\n",
    "            'so_team1_wickets': so_scores[so_scores['batting_team']==so_team1_name]['wickets'].iloc[0],\n",
    "            'so_team1_balls_faced': so_scores[so_scores['batting_team']==so_team1_name]['balls'].iloc[0],\n",
    "            'so_team2_score': so_scores[so_scores['batting_team']==so_team2_name]['runs'].iloc[0],\n",
    "            'so_team2_wickets': so_scores[so_scores['batting_team']==so_team2_name]['wickets'].iloc[0],\n",
    "            'so_team2_balls_faced': so_scores[so_scores['batting_team']==so_team2_name]['balls'].iloc[0]\n",
    "            }\n",
    "            so_match_summary_df = pd.DataFrame([so_match_summary])\n",
    "    return pd.DataFrame([summary]), so_match_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_deliveries_data = []\n",
    "all_match_summaries = []\n",
    "all_so_match_summaries = []\n",
    "for filename in os.listdir('matches'):\n",
    "    deliveries_df = get_delivries_data(filename)\n",
    "    match_summary_df, so_match_df = get_match_summary(filename,deliveries_df)\n",
    "    all_deliveries_data.append(deliveries_df)\n",
    "    all_match_summaries.append(match_summary_df)\n",
    "    if so_match_df is not None:\n",
    "        all_so_match_summaries.append(so_match_df)\n",
    "all_deliveries_df = pd.concat(all_deliveries_data,ignore_index=True)\n",
    "all_match_summary_df = pd.concat(all_match_summaries,ignore_index=True)\n",
    "all_so_match_summaries_df = pd.concat(all_so_match_summaries,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_deliveries_df.to_csv('data_files/ball_by_ball.csv')\n",
    "all_match_summary_df.to_csv('data_files/match_details.csv')\n",
    "all_so_match_summaries_df.to_csv('data_files/super_over_details.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
